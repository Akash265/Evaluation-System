{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data \n",
    "import os\n",
    "import random \n",
    "import itertools\n",
    "import warnings\n",
    "from typing import List\n",
    "\n",
    "from langchain.chains import QAGenerationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,MarkdownTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema,StructuredOutputParser\n",
    "import json\n",
    "## querying the model with the prompt template\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "teacher_prompt_template = \"\"\"You are the teacher in a quiz setting, and the student has requested question in detail for evaluation based on the text provided. The student can choose the type of question: coding, MCQ (multiple-choice), or theoretical. Provide a suitable question and its answer based on the chosen type.Please focus on the type of question asked , it is important to give exactly that kind of question as specified by the student.\n",
    "\n",
    "\n",
    "TEXT: {text} # text on which the question will be based on \n",
    "QUESTION TYPE: {question_type}  # Specify 'coding', 'mcq', or 'theoretical'\n",
    "\n",
    "# Based on the chosen question type, generate a question and answer.\n",
    "If the question type is coding also write the code you are refrencing in the question or with which the question is related to. \n",
    "QUESTION: question\n",
    "ANSWER: answer\n",
    "\n",
    "\"\"\"\n",
    "teacher_prompt_template2 = \"\"\"You are the teacher in a quiz setting, and the student has requested a coding question with answer based on the text provided.Provide a suitable coding question and its answer.\n",
    "\n",
    "\n",
    "\n",
    "Everything between the ``` must be valid json.\n",
    "\n",
    "Please come up with a question/answer pair, in the specified JSON format, for the following text:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "templ = \"\"\"You are a smart assistant designed to help high school teachers come up with reading comprehension questions.\n",
    "Given a piece of text, you must come up with a question and answer pair that can be used to test a student's reading comprehension abilities.\n",
    "When coming up with this question/answer pair, you must respond in the following format:\n",
    "```\n",
    "{{\n",
    "    \"question\": \"$YOUR_QUESTION_HERE\",\n",
    "    \"answer\": \"$THE_ANSWER_HERE\"\n",
    "}}\n",
    "```\n",
    "\n",
    "Everything between the ``` must be valid json.\n",
    "\n",
    "Please come up with a question/answer pair, in the specified JSON format, for the following text:\n",
    "----------------\n",
    "{text}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "question_schema = ResponseSchema(name=\"question\",\n",
    "                             description=\"This is the detailed specific type question based on the text as requested by the student\")\n",
    "\n",
    "answer_schema = ResponseSchema(name=\"answer\",\n",
    "                                      description=\"This is the answer to the question generated \")\n",
    "\n",
    "\n",
    "response_schemas = [question_schema,\n",
    "                    answer_schema\n",
    "                    ]\n",
    "     \n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "QA_PROMPT_TEMPLATE = PromptTemplate(\n",
    "    input_variables=[\"text\",\"question_type\"],\n",
    "    template=teacher_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate.from_template(templ)\n",
    "\n",
    "def generate_eval(text: str, num_questions: int, chunk: int,question_type: str):\n",
    "    \"\"\"\n",
    "    Generate eval set\n",
    "    @param text: text to generate eval set from\n",
    "    @param num_questions: number of questions to generate\n",
    "    @param chunk: chunk size to draw question from in the doc\n",
    "    @return: eval set as JSON list\n",
    "    \"\"\"\n",
    "    #length of text\n",
    "    n = len(text)\n",
    "    if n < chunk:\n",
    "        raise ValueError(\"Text length should be greater than or equal to the chunk size.\")\n",
    "    #starting indices of random chunks \n",
    "    starting_indices = [random.randint(0, n - chunk) for _ in range(num_questions)]\n",
    "    #getting chunks from indices\n",
    "    sub_sequences = [text[i:i + chunk] for i in starting_indices]\n",
    "    \n",
    "    # Set the grading prompt based on the grade_answer_prompt parameter\n",
    "    prompt =QA_PROMPT_TEMPLATE\n",
    "\n",
    "    #Initializing QAGeneration chain\n",
    "    \n",
    "    chain = LLMChain(llm=OpenAI(), prompt=prompt)\n",
    "\n",
    "    #chain = QAGenerationChain.from_llm(llm=OpenAI(),prompt=prompt)\n",
    "    eval_set = []\n",
    "\n",
    "    # Generate a cool name based on the template\n",
    "    response=chain.run(text=sub_sequences,question_type=question_type,number=num_questions)\n",
    "    \n",
    "    # Print the raw response for debugging\n",
    "    print(\"Raw Response:\", response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Response: QUESTION: Which algorithm is used to minimize the cost function J in linear regression?\n",
      "a) Gradient Descent\n",
      "b) Stochastic Gradient Descent\n",
      "c) Normal Equation\n",
      "d) Batch Gradient Descent\n",
      "ANSWER: d) Batch Gradient Descent\n"
     ]
    }
   ],
   "source": [
    "res=generate_eval(text,1,300,'mcq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "res='''\n",
    "Raw Response: MCQ: What does the decorator in FastAPI indicate?\n",
    "a) The URL path of the function.\n",
    "b) The type of data to be returned.\n",
    "c) The HTTP method that the function will respond to.\n",
    "d) The name of the routing function.\n",
    "\n",
    "ANSWER: c) The HTTP method that the function will respond to.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What does the decorator in FastAPI indicate?\\na) The URL path of the function.\\nb) The type of data to be returned.\\nc) The HTTP method that the function will respond to.\\nd) The name of the routing function.', 'answer': 'c) The HTTP method that the function will respond to.'}\n"
     ]
    }
   ],
   "source": [
    "# Splitting the response into question and answer parts\n",
    "try:\n",
    "        split_response = res.split(\"QUESTION:\")[1]\n",
    "except:\n",
    "        split_response = res.split(\"MCQ:\")[1]\n",
    "question = split_response.split(\"ANSWER:\")[0].strip()\n",
    "answer = split_response.split(\"ANSWER:\")[1].strip()\n",
    "\n",
    "# Creating a dictionary\n",
    "response_dict = {\n",
    "    \"question\": question,\n",
    "    \"answer\": answer\n",
    "}\n",
    "\n",
    "print(response_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What does the decorator in FastAPI indicate?\\na) The URL path of the function.\\nb) The type of data to be returned.\\nc) The HTTP method that the function will respond to.\\nd) The name of the routing function.'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_response = res.split(\"MCQ:\")\n",
    "split_response[1].split('ANSWER:')[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: Write the code for the batch gradient descent algorithm.\n",
      "\n",
      ": The code for the batch gradient descent algorithm would depend on the programming language being used. In general, it would involve using a loop to iterate through the data set, calculating the gradients using the partial derivatives, and updating the values of B0 and B1 accordingly. An example of the code in Python might look like this:\n",
      "\n",
      "```\n",
      "# Initialize values of B0 and B1\n",
      "B0 = 0\n",
      "B1 = 0\n",
      "\n",
      "# Set learning rate\n",
      "alpha = 0.01\n",
      "\n",
      "# Set number of iterations\n",
      "num_iterations = 1000\n",
      "\n",
      "# Loop through data set\n",
      "for i in range(num_iterations):\n",
      "  # Calculate gradients using partial derivatives\n",
      "  d_B0 = 0\n",
      "  d_B1 = 0\n",
      "  for data_point in data_set:\n",
      "    d_B0 += (B0 + B1 * data_point[0] - data_point[1])\n",
      "    d_B1 += (B0 + B1 * data_point[0] - data_point[1]) * data_point[0]\n",
      "\n",
      "  # Update values of B0 and B1\n",
      "  B0 = B0 - alpha * d_B0\n",
      "  B1 = B1\n"
     ]
    }
   ],
   "source": [
    "for r in res.split('ANSWER'):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no. of users, courses ,no. of documents generated ,no. of documents-ready, no. of documents-processing ,main dashboard, saturday deadline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "# Function to change our long text about a person into documents\n",
    "def split_text(user_information):\n",
    "    # First we make our text splitter\n",
    "    text_splitter = MarkdownTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "\n",
    "    # Then we split our user information into different documents\n",
    "    docs = text_splitter.create_documents([user_information])\n",
    "\n",
    "    return docs\n",
    "\n",
    "# Prompts - We'll do a dynamic prompt based on the option the users selects\n",
    "# We'll hold different instructions in this dictionary below\n",
    "response_types = {\n",
    "    'Interview Questions' : \"\"\"\n",
    "        Your goal is to generate interview questions that we can ask them\n",
    "        Please respond with list of a few interview questions based on the topics above\n",
    "    \"\"\",\n",
    "    '1-Page Summary' : \"\"\"\n",
    "        Your goal is to generate a 1 page summary about them\n",
    "        Please respond with a few short paragraphs that would prepare someone to talk to this person\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "map_prompt = \"\"\"You are a helpful AI bot that aids a user in research.\n",
    "Below is information about a person named {persons_name}.\n",
    "Information will include tweets, interview transcripts, and blog posts about {persons_name}\n",
    "Use specifics from the research when possible\n",
    "\n",
    "{response_type}\n",
    "\n",
    "% START OF INFORMATION ABOUT {persons_name}:\n",
    "{text}\n",
    "% END OF INFORMATION ABOUT {persons_name}:\n",
    "\n",
    "YOUR RESPONSE:\"\"\"\n",
    "map_prompt2=\"\"\"You are a smart assistant designed to help teachers come up with {question_type} questions.\n",
    "Given a piece of text, you must come up with a {question_type} question and answer pair based on text that can be used to test a student's understanding of the text content.\n",
    "When coming up with this {question_type} question/answer pair, you must respond in the following format:\n",
    "```\n",
    "{{\n",
    "    \"question\": \"$YOUR_QUESTION_HERE\",\n",
    "    \"answer\": \"$THE_ANSWER_HERE\"\n",
    "}}\n",
    "```\n",
    "\n",
    "Everything between the ``` must be valid json.\n",
    "\n",
    "Please come up with a {question_type} question/answer pair, in the specified JSON format, for the following text:\n",
    "----------------\n",
    "{text}\"\"\"\n",
    "map_prompt_template = PromptTemplate(template=map_prompt, input_variables=[\"text\", \"persons_name\", \"response_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_prompt = \"\"\"\n",
    "You are a helpful AI bot that aids a user in research.\n",
    "You will be given information about {persons_name}.\n",
    "Do not make anything up, only use information which is in the person's context\n",
    "\n",
    "{response_type}\n",
    "\n",
    "% PERSON CONTEXT\n",
    "{text}\n",
    "\n",
    "% YOUR RESPONSE:\n",
    "\"\"\"\n",
    "combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=[\"text\", \"persons_name\", \"response_type\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_information='ks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_information_docs = split_text(user_information)\n",
    "\n",
    "# Calls the function above\n",
    "llm = ChatOpenAI(temperature=.7, max_tokens=2000, model_name='gpt-4')\n",
    "\n",
    "chain = load_summarize_chain(llm,\n",
    "                                chain_type=\"map_reduce\",\n",
    "                                map_prompt=map_prompt_template,\n",
    "                                combine_prompt=combine_prompt_template,\n",
    "                                # verbose=True\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'person_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Here we will pass our user information we gathered, the persons name and the response type from the radio button\u001b[39;00m\n\u001b[1;32m      2\u001b[0m output \u001b[38;5;241m=\u001b[39m chain({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_information_docs, \u001b[38;5;66;03m# The seven docs that were created before\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpersons_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mperson_name\u001b[49m,\n\u001b[1;32m      4\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_type\u001b[39m\u001b[38;5;124m\"\u001b[39m : response_types[output_type]\n\u001b[1;32m      5\u001b[0m                 })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'person_name' is not defined"
     ]
    }
   ],
   "source": [
    "# Here we will pass our user information we gathered, the persons name and the response type from the radio button\n",
    "output = chain({\"input_documents\": user_information_docs, # The seven docs that were created before\n",
    "                \"persons_name\": person_name,\n",
    "                \"response_type\" : response_types[output_type]\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Markdown file in read mode\n",
    "with open('../1.md', 'r', encoding='utf-8') as file:\n",
    "    # Read the contents of the file\n",
    "    markdown_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(content):\n",
    "    # First we make our text splitter\n",
    "    text_splitter = MarkdownTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "\n",
    "    # Then we split our user information into different documents\n",
    "    docs = text_splitter.create_documents([content])\n",
    "\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4924"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_docs=split_text(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(markdown_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, max_tokens=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema \n",
    "from langchain.output_parsers import StructuredOutputParser \n",
    "brand_name_schema = ResponseSchema(name=\"brand_name\", description=\"This is the name of the brand\") \n",
    "likelihood_of_success_schema = ResponseSchema(name=\"likelihood_of_success\", description=\"This is an integer score between 1-10\") \n",
    "reasoning_schema = ResponseSchema(name=\"reasoning\", description=\"This is the reasons for the score\") \n",
    "response_schemas = [brand_name_schema, likelihood_of_success_schema, reasoning_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Topic(BaseModel):\n",
    "    title: List = Field(description=\"List of {n} titles of the topics extracted from the provided markdown text\")\n",
    "    description: List = Field(description=\"List of {n} descripitons of the topics extracted from the provided markdown text\")\n",
    "\n",
    "output_parser = JsonOutputParser(pydantic_object=Topic)\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_template=\"\"\"Extract {n} different educational topics covered in the provided markdown text from which different questions can be asked.\n",
    "                    Generate {n} different educational topics based on the following text:\n",
    "                    \\n {text_input}\\n\n",
    "                    {format_instructions}\"\"\"\n",
    "TOPIC_TEMPLATE2=\"\"\"\n",
    "Extract {n} educational topics covered in the provided markdown text from which questions can be formulated.\n",
    "Generate {n} educational topics based on the following text:\n",
    "\n",
    "{text_input}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_extraction_prompt = PromptTemplate( input_variables=[\"text_input\",\"n\"] ,partial_variables={\"format_instructions\":format_instructions},template=TOPIC_TEMPLATE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = topic_extraction_prompt | llm | output_parser\n",
    "raw_output=chain.invoke({\"text_input\":markdown_docs,\n",
    "              \"n\":10})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': ['Fast API Routing',\n",
       "  'Understanding Routing in Fast API',\n",
       "  'Path Parameters and Numeric Validations',\n",
       "  'Query Parameters and String Validations',\n",
       "  'Exercises',\n",
       "  '1. Write a FastAPI application with the following routes:',\n",
       "  '2. Modify the \"/items/\" route in the above application to add a string query parameter `sort` with a default value of \"asc\".',\n",
       "  '3. What will happen if you send a GET request to the \"/greet/{name}\" route of the above application without providing a `name` in the URL?',\n",
       "  '4. Explain the role of decorators in FastAPI routing.',\n",
       "  'External Resource Links'],\n",
       " 'description': ['Putting signboards on the code highway to avoid getting lost!',\n",
       "  'Routing in Fast API is a way to direct the incoming HTTP requests to specific resources or functions based on the URL path.',\n",
       "  'Path parameters are variables in the URL path that are processed as input parameters by the routing function.',\n",
       "  'Query parameters are additional inputs provided in the URL after a `?` symbol.',\n",
       "  'Exercises for practicing FastAPI routing concepts.',\n",
       "  'Instructions for writing a FastAPI application with specific routes.',\n",
       "  'Instructions for modifying a route in a FastAPI application.',\n",
       "  'Explanation of potential outcomes when sending a GET request to a specific route in a FastAPI application.',\n",
       "  'Explanation of the role of decorators in FastAPI routing and how they handle different types of HTTP requests.',\n",
       "  'Links to external resources for learning more about FastAPI routing.']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic_1': {'title': 'Fast API Routing',\n",
       "  'description': 'Understanding routing in Fast API and the use of decorators to handle different types of HTTP requests',\n",
       "  'type': 'string'},\n",
       " 'topic_2': {'title': 'Path Parameters and Numeric Validations',\n",
       "  'description': \"Defining and validating path parameters in Fast API using Python's type hints\",\n",
       "  'type': 'string'},\n",
       " 'topic_3': {'title': 'Query Parameters and String Validations',\n",
       "  'description': \"Using query parameters to filter and sort data in Fast API and validating them using Python's built-in type hints\",\n",
       "  'type': 'string'},\n",
       " 'topic_4': {'title': 'External Resource Links',\n",
       "  'description': 'Links to external resources for further learning on Fast API routing',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_extraction_chain = LLMChain(llm=llm, prompt=topic_extraction_prompt,output_parser=output_parser) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt_template=\"\"\"You are a smart assistant designed to help teachers come up with a single detailed {question_type} question.\n",
    "Given a list of topics, you must come up with a detailed {question_type} question that can be used to test a student's understanding of the topic content.\n",
    "Please focus on the type of question asked, that is detailed {question_type} question, only generate a single detailed {question_type} question based on topics.\n",
    "When coming up with this {question_type} question and answer, you must respond in the following format:\n",
    "\n",
    "QUESTION: DETAILED_{question_type}_QUESTION_HERE,\n",
    "ANSWER: THE_ANSWER_HERE\n",
    "\n",
    "Please come up with a single detailed {question_type} question and answer ,in a dictionary format ,from the following list of topics:\n",
    "----------------\n",
    "{topics}\"\"\"\n",
    "QA_PROMPT_TEMPLATE = PromptTemplate(\n",
    "    input_variables=[\"topics\",\"question_type\"],\n",
    "    template=qa_prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "class MCQ(BaseModel):\n",
    "    question: str = Field(description=\"The MCQ Question\")\n",
    "    A:str =Field(description=\"The first option of the MCQ\")\n",
    "    B:str =Field(description=\"The second option of the MCQ\")\n",
    "    C:str =Field(description=\"The third option of the MCQ\")\n",
    "    D:str =Field(description=\"The fourth option of the MCQ\")\n",
    "    answer:str = Field(description=\"Answer of the MCQ Question\")\n",
    "\n",
    "output_parser = JsonOutputParser(pydantic_object=MCQ)\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "class Coding(BaseModel):\n",
    "    question: str = Field(description=\"The Coding Question along with the code (if required)\")\n",
    "    answer:str = Field(description=\"Code answer in language specified in the question\")\n",
    "\n",
    "output_parser = JsonOutputParser(pydantic_object=MCQ)\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt_template=\"\"\"You are a smart assistant designed to help teachers come up with detailed {question_type} question.\n",
    "Given a topic, you must come up with a detailed {question_type} question that can be used to test a student's understanding of the topic .\n",
    "Please focus on the type of question asked, that is detailed {question_type} question, only generate a single detailed {question_type} question based on the topic.\n",
    "\n",
    "Please come up with a single detailed {question_type} question and answer ,in a dictionary format ,from the following topic:\n",
    "----------------\n",
    "TOPIC TITLE: {topic_title}\n",
    "TOPIC DESCRIPTION: {topic_description}\\n\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "qa_prompt_template2=\"\"\"\n",
    "You are a smart assistant designed to help teachers come up with detailed {question_type} questions.\n",
    "Given a topic, your task is to generate a detailed {question_type} question aimed at testing a student's understanding of the topic.\n",
    "Please focus on crafting a single detailed {question_type} question along with its answer, presented in a dictionary format, based on the provided topic:\n",
    "\n",
    "----------------\n",
    "TOPIC TITLE: {topic_title}\n",
    "TOPIC DESCRIPTION: {topic_description}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "QA_PROMPT_TEMPLATE = PromptTemplate(\n",
    "    input_variables=[\"topics\",\"question_type\",\"topic_title\",\"topic_description\"],\n",
    "    partial_variables={\"format_instructions\":format_instructions},\n",
    "    template=qa_prompt_template2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the grading prompt based on the grade_answer_prompt parameter\n",
    "question_type='MCQ'\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(name='gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = QA_PROMPT_TEMPLATE | llm | output_parser\n",
    "raw_output=chain.invoke({\"topic_title\":topics[f\"topic_{i+1}\"][\"title\"],\"topic_description\":topics[f\"topic_{i+1}\"][\"description\"],\"question_type\":question_type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which of the following decorators is used to handle GET requests in Fast API routing?\n",
      "????????????????????????????????????\n",
      "@app.get\n",
      "????????????????????????????????????\n",
      "@app.post\n",
      "????????????????????????????????????\n",
      "@app.put\n",
      "????????????????????????????????????\n",
      "@app.delete\n",
      "????????????????????????????????????\n",
      "A\n",
      "????????????????????????????????????\n"
     ]
    }
   ],
   "source": [
    "for i in raw_output.keys():\n",
    "    print(raw_output[i])\n",
    "    print('????????????????????????????????????')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Create a Fast API endpoint that accepts a path parameter for a specific user and a query parameter for sorting the user's data by date. The endpoint should return a JSON response with the sorted data.\",\n",
       " 'question_code': \"from fastapi import FastAPI\\n\\napp = FastAPI()\\n\\n@app.get('/users/{user_id}')\\ndef get_user_data(user_id: int, sort_by: str):\\n    # code to retrieve user data\\n    # code to sort data by date\\n    # return sorted data as JSON response\",\n",
       " 'answer': \"from fastapi import FastAPI\\n\\napp = FastAPI()\\n\\n@app.get('/users/{user_id}')\\ndef get_user_data(user_id: int, sort_by: str):\\n    # code to retrieve user data\\n    # code to sort data by date\\n    # return sorted data as JSON response\"}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from fastapi import FastAPI\n",
      "\n",
      "app = FastAPI()\n",
      "\n",
      "@app.get('/users/{user_id}')\n",
      "def get_user_data(user_id: int, sort_by: str):\n",
      "    # code to retrieve user data\n",
      "    # code to sort data by date\n",
      "    # return sorted data as JSON response\n"
     ]
    }
   ],
   "source": [
    "print(raw_output['question_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Response: \n",
      "\n",
      "QUESTION: What is the role of decorators in Fast API routing?\n",
      "ANSWER: Decorators are used to define the path and HTTP method for a specific function, allowing Fast API to handle different types of HTTP requests.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Initializing QAGeneration chain\n",
    "i=0\n",
    "chain = LLMChain(llm=OpenAI(temperature=0,max_tokens=2000),prompt=QA_PROMPT_TEMPLATE)\n",
    "\n",
    "\n",
    "#chain = QAGenerationChain.from_llm(llm=OpenAI())\n",
    "eval_set = []\n",
    "\n",
    "# Generate a cool name based on the template\n",
    "response=chain.run(topic_title=topics[f\"topic_{i+1}\"][\"title\"],topic_description=topics[f\"topic_{i+1}\"][\"description\"],question_type=question_type)\n",
    "# Print the raw response for debugging\n",
    "print(\"Raw Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(response):\n",
    "    try:\n",
    "        split_response = response.split(\"QUESTION:\")[1]\n",
    "    except:\n",
    "        split_response = response.split(\"MCQ:\")[1]\n",
    "    question = split_response.split(\"ANSWER:\")[0].strip()\n",
    "    answer = split_response.split(\"ANSWER:\")[1].strip()\n",
    "\n",
    "    # Creating a dictionary\n",
    "    response_dict = {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "    }\n",
    "    return response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the purpose of using decorators in FastAPI routing?\\nA) To add additional functionality to the route\\nB) To specify the HTTP method for the route\\nC) To validate path parameters\\nD) To handle query parameters',\n",
       " 'answer': 'A) To add additional functionality to the route'}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MCQ (Multiple Choice Question)'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "\n",
    "def convert_to_markdown(text):\n",
    "    return markdown.markdown(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>QUESTION: Write a FastAPI endpoint that accepts a path parameter for a user\\'s ID and a query parameter for their preferred language. The endpoint should return a JSON response with the user\\'s ID, name, and preferred language.\\nANSWER:\\n@app.get(\"/user/{id}\")\\ndef get_user(id: int, language: str):\\n    # code to retrieve user information from database\\n    return {\"id\": id, \"name\": user.name, \"language\": language}</p>'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_markdown(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_prompt_template = \"\"\"You are the teacher in a quiz setting, and the student has requested question in detail for evaluation based on the text provided. The student can choose the type of question: coding, MCQ (multiple-choice), or theoretical. Provide a suitable question and its answer based on the chosen type.Please focus on the type of question asked , it is important to give exactly that kind of question as specified by the student.\n",
    "\n",
    "\n",
    "TEXT: {text} # text on which the question will be based on \n",
    "QUESTION TYPE: {question_type}  # Specify 'coding', 'mcq', or 'theoretical'\n",
    "\n",
    "# Based on the chosen question type, generate a question and answer.\n",
    "If the question type is coding also write the code you are refrencing in the question or with which the question is related to. \n",
    "QUESTION: question\n",
    "ANSWER: answer\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt_template=\"\"\"You are a smart assistant designed to help teachers come up with detailed {question_type} question.\n",
    "Given a topic, you must come up with a detailed {question_type} question that can be used to test a student's understanding of the topic .\n",
    "Please focus on the type of question asked, that is detailed {question_type} question, only generate a single detailed {question_type} question based on the topic.\n",
    "When coming up with this {question_type} question and answer, you must respond in the following format:\n",
    "\n",
    "QUESTION: DETAILED_{question_type}_QUESTION_HERE,\n",
    "ANSWER: THE_ANSWER_HERE\n",
    "\n",
    "Please come up with a single detailed {question_type} question and answer ,in a dictionary format ,from the following topic:\n",
    "----------------\n",
    "TOPIC TITLE: {topic_title}\n",
    "TOPIC DESCRIPTION: {topic_description}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your desired data structure.\n",
    "class Topic(BaseModel):\n",
    "    topic_name: str = Field(description=\"Name of Topic extracted from the provided markdown text\")\n",
    "    topic_description: str = Field(description=\"Description of Topic extracted from the provided markdown text\")\n",
    "\n",
    "output_parser = JsonOutputParser(pydantic_object=Topic)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "topic_template=\"\"\"Extract {n} educational topics covered in the provided markdown text from which question can be asked.\n",
    "                    Generate {n} educational topics based on the following text:\n",
    "                    \\n {text_input}\\n\n",
    "                    {format_instructions}\"\"\"\n",
    "                    \n",
    "topic_extraction_prompt = PromptTemplate( input_variables=[\"text_input\",\"n\"] ,partial_variables={\"format_instructions\":format_instructions},template=topic_template)\n",
    "\n",
    "QA_PROMPT_TEMPLATE1 = PromptTemplate(\n",
    "    input_variables=[\"question_type\",\"topic_title\",\"topic_description\"],\n",
    "    template=qa_prompt_template)\n",
    "\n",
    "QA_PROMPT_TEMPLATE2 = PromptTemplate(\n",
    "    input_variables=[\"text\",\"question_type\"],\n",
    "    template=teacher_prompt_template,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(content):\n",
    "    # First we make our text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "    # Then we split our user information into different documents\n",
    "    docs = text_splitter.create_documents([content])\n",
    "\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../example.txt','r') as f:\n",
    "    lines=f.readlines()\n",
    "text=''.join([line.replace('\\n',' ')for line in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_questions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 3\u001b[0m markdown_docs\u001b[38;5;241m=\u001b[39m\u001b[43msplit_text\u001b[49m(text)\n\u001b[1;32m      4\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m chain \u001b[38;5;241m=\u001b[39m topic_extraction_prompt \u001b[38;5;241m|\u001b[39m llm \u001b[38;5;241m|\u001b[39m output_parser\n",
      "\u001b[0;31mNameError\u001b[0m: name 'split_text' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "num_questions=5\n",
    "\n",
    "markdown_docs=split_text(text)\n",
    "llm = OpenAI(temperature=0)\n",
    "chain = topic_extraction_prompt | llm | output_parser\n",
    "raw_output=chain.invoke({\"text_input\":markdown_docs,\n",
    "            \"n\":num_questions})\n",
    "topics=raw_output['properties']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'markdown_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmarkdown_docs\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'markdown_docs' is not defined"
     ]
    }
   ],
   "source": [
    "markdown_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(markdown_docs[0].to_json()['kwargs']['page_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_eval(text: str, num_questions: int, chunk: int,question_type: str):\n",
    "    \"\"\"\n",
    "    Generate eval set\n",
    "    @param text: text to generate eval set from\n",
    "    @param num_questions: number of questions to generate\n",
    "    @param chunk: chunk size to draw question from in the doc\n",
    "    @return: eval set as JSON list\n",
    "    \"\"\"\n",
    "    #length of text\n",
    "    n = len(text)\n",
    "    if n < chunk:\n",
    "        raise ValueError(\"Text length should be greater than or equal to the chunk size.\")\n",
    "    #starting indices of random chunks \n",
    "    markdown_docs=split_text(text)\n",
    "    llm = OpenAI(temperature=0, max_tokens=2000)\n",
    "    chain = topic_extraction_prompt | llm | output_parser\n",
    "    raw_output=chain.invoke({\"text_input\":markdown_docs,\n",
    "                \"n\":num_questions})\n",
    "    topics=raw_output['properties']\n",
    "    # Set the grading prompt based on the grade_answer_prompt parameter\n",
    "    chain = LLMChain(llm=OpenAI(temperature=0,max_tokens=2000),prompt=QA_PROMPT_TEMPLATE1)\n",
    "    eval_set=[]\n",
    "\n",
    "    #Initializing QAGeneration chain\n",
    "    for i in range(num_questions):\n",
    "        # Generate a cool name based on the template\n",
    "\n",
    "        response=chain.run(topic_title=topics[f\"topic_{i+1}\"][\"title\"],topic_description=topics[f\"topic_{i+1}\"][\"description\"],question_type=question_type)\n",
    "        parsed_response=parse(response)\n",
    "        eval_set.append(parsed_response)\n",
    "    return eval_set\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
